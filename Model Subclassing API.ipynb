{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 22.6988 - binary_accuracy: 0.3500 - val_loss: 14.0880 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 337ms/step - loss: 4.5126 - binary_accuracy: 0.5000 - val_loss: 1.1604 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.7062 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.8878 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.8546 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6931 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931478381156921, 0.5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (3, 3), activation='relu')\n",
    "        self.pool1 = MaxPooling2D((2, 2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        output = self.dense2(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Define ImageDataGenerator for normalizing pixel values\n",
    "normalize_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "normalize_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load train data using ImageDataGenerator with shuffling\n",
    "train_data = normalize_train.flow_from_directory(\n",
    "    r\"C:\\Users\\aethe\\Desktop\\work\\EDA\\dataset\\train\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=15,\n",
    "    class_mode='binary',  # Set class_mode to 'binary' for binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load test data using ImageDataGenerator with shuffling\n",
    "test_data = normalize_test.flow_from_directory(\n",
    "    r\"C:\\Users\\aethe\\Desktop\\work\\EDA\\dataset\\test\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=15,\n",
    "    class_mode='binary',  # Set class_mode to 'binary' for binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomModel()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[BinaryAccuracy()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, epochs=5, validation_data=test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 17.6061 - binary_accuracy: 0.1500 - val_loss: 1.0380 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 2.1725 - binary_accuracy: 0.5000 - val_loss: 0.5490 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3904 - binary_accuracy: 0.7500 - val_loss: 0.1460 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1938 - binary_accuracy: 0.9000 - val_loss: 0.1474 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.6384 - binary_accuracy: 0.8000 - val_loss: 0.5406 - val_binary_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5406 - binary_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5406013131141663, 0.6666666865348816]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "class CustomConv2D(Layer):\n",
    "    def __init__(self, filters, kernel_size, activation='relu'):\n",
    "        super(CustomConv2D, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(self.kernel_size[0], self.kernel_size[1], input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True,\n",
    "                                      name='kernel')\n",
    "        self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True,\n",
    "                                    name='bias')\n",
    "        # super(CustomConv2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.nn.conv2d(inputs, self.kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        output = tf.nn.bias_add(output, self.bias)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "class CustomDense(Layer):\n",
    "    def __init__(self, units, activation='relu'):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True,\n",
    "                                      name='kernel')\n",
    "        self.bias = self.add_weight(shape=(self.units,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True,\n",
    "                                    name='bias')\n",
    "        # super(CustomDense, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.matmul(inputs, self.kernel)\n",
    "        output = tf.nn.bias_add(output, self.bias)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = CustomConv2D(32, (3, 3), activation='relu')\n",
    "        self.pool1 = MaxPooling2D((2, 2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = CustomDense(64, activation='relu')\n",
    "        self.dense2 = CustomDense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        output = self.dense2(x)\n",
    "        return output\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            loss = self.compiled_loss(y, y_pred)  # Compute loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update metrics\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Define ImageDataGenerator for normalizing pixel values\n",
    "normalize_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "normalize_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load train data using ImageDataGenerator with shuffling\n",
    "train_data = normalize_train.flow_from_directory(\n",
    "    r\"C:\\Users\\aethe\\Desktop\\work\\EDA\\dataset\\train\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=15,\n",
    "    class_mode='binary',  # Set class_mode to 'binary' for binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load test data using ImageDataGenerator with shuffling\n",
    "test_data = normalize_test.flow_from_directory(\n",
    "    r\"C:\\Users\\aethe\\Desktop\\work\\EDA\\dataset\\test\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=15,\n",
    "    class_mode='binary',  # Set class_mode to 'binary' for binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomModel()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[BinaryAccuracy()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, epochs=5, validation_data=test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
